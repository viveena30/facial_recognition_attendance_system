{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "from datetime import datetime\n",
    "# from PIL import ImageGrab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgElon = face_recognition.load_image_file('Images/Elon_Musk.jpg')\n",
    "# imgElon = cv2.cvtColor(imgElon,cv2.COLOR_BGR2RGB) #converting it to RGB\n",
    "# imgTest = face_recognition.load_image_file('Images/Elon_test.jpeg')\n",
    "# imgTest = cv2.cvtColor(imgTest,cv2.COLOR_BGR2RGB) \n",
    "\n",
    "# faceLoc = face_recognition.face_locations(imgElon)[0] \n",
    "# encodeElon = face_recognition.face_encodings(imgElon)[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "instead of writing the above code for every image we will write code so that the images are taken from our folder automatically\n",
    "and then it will generate the encoding automatically and then it will try to find it in our webcam (the image we will get using our webcam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bill_Gates', 'deekshant_rawat', 'Elon_Musk', 'Jack_ma', 'Jeff_Bezos']\n"
     ]
    }
   ],
   "source": [
    "path = 'ImagesAttendance'\n",
    "images = []\n",
    "classNames = []\n",
    "myList = os.listdir(path)\n",
    "# print(myList)\n",
    "for cl in myList:\n",
    "    curImg = cv2.imread(f'{path}/{cl}') #cl is the name of our image\n",
    "    images.append(curImg)\n",
    "    classNames.append(os.path.splitext(cl)[0])\n",
    "print(classNames) #name of images without encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Complete\n"
     ]
    }
   ],
   "source": [
    "#encoding process : we  have to find encoding for each one of them.\n",
    "\n",
    "#we can create a simple function for this\n",
    "\n",
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "    return encodeList\n",
    "\n",
    "encodeListKnown = findEncodings(images)\n",
    "print('Encoding Complete')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markAttendance(name):\n",
    "    with open('Attendance.csv','r+') as f: \n",
    "        #storing the vlaues in cvs file, we will store Name and Time\n",
    "        myDataList = f.readlines()\n",
    "        #reading all the lines that we currently have in our data or file bcz if someone is already arrived we do not want to repeat it\n",
    "#         print(myDataList)\n",
    "        nameList = []\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            dateString = now.strftime('%H:%M:%S')\n",
    "            f.writelines(f'\\n{name},{dateString}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Find the matches between our encodings \n",
    "#but we dont have an image to macth it with, now that image will be coming \n",
    "#from our webcam\n",
    "\n",
    "#initialising the web cam\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#to get each frame one by one \n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgS = cv2.resize(img,(0,0),None,0.25,0.25) #to speed up the process reducing the size of image\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "\n",
    "    \n",
    "#in the webcam we may find multiple face so for that we are going to find the location of our faces then we are going to send in these locations \n",
    "#to our encoding function to find locations:\n",
    "    facesCurFrame = face_recognition.face_locations(imgS)\n",
    "    \n",
    "    # next step is to find the encoding of our web cam image\n",
    "    encodesCurFrame = face_recognition.face_encodings(imgS,facesCurFrame)\n",
    "    \n",
    "#now moving to our main 3rd step where we are finding the matches\n",
    "\n",
    "#iterate through all the faces that we have found in our current frame and then compare all these faces with all\n",
    "#the encodings that we found before\n",
    "\n",
    "    for encodeFace,faceLoc in zip(encodesCurFrame,facesCurFrame): #one by one it will grab one face location from the facesCurFrame list and the it will grab the encoding of encodeFace from encodesCurFrame\n",
    "    #we want them in the same loop that's why we are using them\n",
    "        matches = face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
    "        faceDis = face_recognition.face_distance(encodeListKnown,encodeFace)\n",
    "        #we are sending a list encodeListKnown in our face_distance func so it will return us a list as well\n",
    "        #it will give us 4 values as we have 4 values as we have 4 known faces and it will give us the distance of \n",
    "        #each one of them,so the lowest distance will be our best match\n",
    "        \n",
    "        #print(faceDis)\n",
    "        matchIndex = np.argmin(faceDis) #index at which our face distance is min\n",
    "        \n",
    "        #once we have that index we know which person we are talking about\n",
    "        \n",
    "        #so we can display a bounding box around them and we can write their name\n",
    "        \n",
    "        if matches[matchIndex]:\n",
    "            name = classNames[matchIndex].upper()\n",
    "            #print(name)\n",
    "            #surrounding face with box\n",
    "            y1,x2,y2,x1 = faceLoc\n",
    "            y1,x2,y2,x1 = y1*4,x2*4,y2*4,x1*4 #as we have scaled down the images so again increasing its size\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
    "            cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "            markAttendance(name)\n",
    "    cv2.imshow('Webcam',img)\n",
    "    cv2.waitKey(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
